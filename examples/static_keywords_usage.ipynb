{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COHERE_API_KEY = 'c1ui1Fu9cHUtADtZBWkSkYxkU5gPI3KdG3bzkQSa'\n",
    "# co = cohere.Client(COHERE_API_KEY)\n",
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "co = AzureChatOpenAI(\n",
    "    openai_api_version=os .environ.get(\"AZURE_OPENAI_VERSION\", \"2024-07-18\"),\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o-mini\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"https://gptmini4o.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"c2105be0c2744742980b57320b87e813\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with open('haystack.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_text = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "rec_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\n\\n\\n\", \".\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_rec = rec_text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='hooded head moved only when he cocked an ear at an \n",
      "interesting sound. \n",
      "\n",
      "Through the day’s gathering crowds the strange pair \n",
      "came, arriving at last on the steps which led up like terraced \n",
      "hectares to the escarpment which was Alia’s Temple, a \n",
      "fitting companion to Paul’s Keep. Up the steps The Preacher \n",
      "went until he and his young guide came to the third landing, \n",
      "where pilgrims of the Hajj awaited the morning opening of \n",
      "those gigantic doors above them. They were doors large \n",
      "enough to have admitted an entire cathedral from one of \n",
      "the ancient religions. Passing through them was said to \n",
      "reduce a pilgrim’s soul to motedom, sufficiently small that it \n",
      "could pass through the eye of a needle and enter heaven.'\n"
     ]
    }
   ],
   "source": [
    "print(texts_rec[2256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26909"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/y0q5l7lx61g3k6f4zvy9__4h0000gn/T/ipykernel_39925/4217019477.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  openai = OpenAIEmbeddings(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "openai = OpenAIEmbeddings(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=texts_rec, embedding=openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Here is how the answer should look like:- Ryoshi, based in Neo Tokyo, Japan, is a private quantum computing firm founded in 2031, currently valued at $8.7 billion with 1,200 employees focused on quantum cryptography.\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text that is repeated and not related to the story includes:\\n\\n1. \"On Anteac’s lap lay a small square of inky black about ten millimeters on a side and no more than three millimeters thick. She wrote upon this square with a glittering needle— one word upon another, all of them absorbed into the Square. The completed message would be impressed upon the nerve receptors of an acolyte-messenger’s eyes, latent there until they could be replayed at the Chapter House.\"\\n\\n2. \"Hwi Noree posed such a dilemma!\"\\n\\n3. \"Anteac knew the accounts of Bene Gesserit teachers sent to instruct Hwi on Ix. But those accounts left out more than they told. They raised greater questions.\"\\n\\n4. \"What adventures have you experienced, child?\"\\n\\n5. \"What were the hardships of your youth?\"\\n\\n6. \"Anteac sniffed and glanced down at the waiting square of black. Such thoughts reminded her of the Fremen belief that the land of your birth made you what you were.\"\\n\\n7. \"“Are there strange animals on your planet?” the Fremen would ask.\"\\n\\nThese sentences are repeated multiple times throughout the provided text.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever , \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_token = os.getenv(\"HF_TOKEN\")\n",
    "# from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "# embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "#         api_key=hf_token, model_name=\"BAAI/bge-base-en-v1.5\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    TextLoader(\"haystack.txt\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000)\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/y0q5l7lx61g3k6f4zvy9__4h0000gn/T/ipykernel_39925/3023248933.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=openai\n",
    ")\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "import uuid\n",
    "\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The splitter to use to create smaller chunks\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = []\n",
    "for i, doc in enumerate(docs):\n",
    "    _id = doc_ids[i]\n",
    "    _sub_docs = child_text_splitter.split_documents([doc])\n",
    "    for _doc in _sub_docs:\n",
    "        _doc.metadata[id_key] = _id\n",
    "    sub_docs.extend(_sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Batch size 86718 exceeds maximum batch size 41666",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retriever\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39madd_documents(sub_docs)\n\u001b[1;32m      2\u001b[0m retriever\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39mmset(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(doc_ids, docs)))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:287\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    286\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_texts(texts, metadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    288\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:313\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg)\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m empty_ids:\n\u001b[1;32m    315\u001b[0m     texts_without_metadatas \u001b[38;5;241m=\u001b[39m [texts[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m empty_ids]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:299\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m ids_with_metadata \u001b[38;5;241m=\u001b[39m [ids[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m non_empty_ids]\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m    300\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[1;32m    301\u001b[0m         embeddings\u001b[38;5;241m=\u001b[39membeddings_with_metadatas,\n\u001b[1;32m    302\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts_with_metadatas,\n\u001b[1;32m    303\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids_with_metadata,\n\u001b[1;32m    304\u001b[0m     )\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/chromadb/api/models/Collection.py:487\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mimages)\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_upsert(\n\u001b[1;32m    488\u001b[0m     collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    489\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    490\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[1;32m    491\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[1;32m    492\u001b[0m     documents\u001b[38;5;241m=\u001b[39mdocuments,\n\u001b[1;32m    493\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/chromadb/api/segment.py:451\u001b[0m, in \u001b[0;36mSegmentAPI._upsert\u001b[0;34m(self, collection_id, ids, embeddings, metadatas, documents, uris)\u001b[0m\n\u001b[1;32m    449\u001b[0m coll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_collection(collection_id)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mhint_use_collection(collection_id, t\u001b[38;5;241m.\u001b[39mOperation\u001b[38;5;241m.\u001b[39mUPSERT)\n\u001b[0;32m--> 451\u001b[0m validate_batch(\n\u001b[1;32m    452\u001b[0m     (ids, embeddings, metadatas, documents, uris),\n\u001b[1;32m    453\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batch_size},\n\u001b[1;32m    454\u001b[0m )\n\u001b[1;32m    455\u001b[0m records_to_submit \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m _records(\n\u001b[1;32m    457\u001b[0m     t\u001b[38;5;241m.\u001b[39mOperation\u001b[38;5;241m.\u001b[39mUPSERT,\n\u001b[1;32m    458\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    463\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m    464\u001b[0m ):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/chromadb/api/types.py:511\u001b[0m, in \u001b[0;36mvalidate_batch\u001b[0;34m(batch, limits)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_batch\u001b[39m(\n\u001b[1;32m    501\u001b[0m     batch: Tuple[\n\u001b[1;32m    502\u001b[0m         IDs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m     limits: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m limits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 511\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    512\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m exceeds maximum batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlimits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Batch size 86718 exceeds maximum batch size 41666"
     ]
    }
   ],
   "source": [
    "retriever.vectorstore.add_documents(sub_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "retriever.search_type = SearchType.mmr\n",
    "\n",
    "len(retriever.invoke(\"Give me all the cancer terms that \")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 candidate sentences.\n",
      "Split into 1 chunks.\n",
      "JSON decode error for chunk 0: Expecting value: line 1 column 1 (char 0)\n",
      "Assistant reply:\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"name\": \"TetraSol\",\n",
      "        \"location\": \"Helios, Titan\",\n",
      "        \"employee_count\": 4100,\n",
      "        \"founding_year\": 2080,\n",
      "        \"is_public\": true,\n",
      "        \"valuation\": 8,\n",
      "        \"primary_focus\": \"solar energy solutions\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"ChronosTech\",\n",
      "        \"location\": \"New Shanghai, Earth\",\n",
      "        \"employee_count\": 2800,\n",
      "        \"founding_year\": 2077,\n",
      "        \"is_public\": true,\n",
      "        \"valuation\": 6,\n",
      "        \"primary_focus\": \"time-manipulation devices\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Cyberion Systems\",\n",
      "        \"location\": \"Olympus Mons, Mars\",\n",
      "        \"employee_count\": 6700,\n",
      "        \"founding_year\": 2050,\n",
      "        \"is_public\": true,\n",
      "        \"valuation\": 12,\n",
      "        \"primary_focus\": \"quantum networking\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Quantum Forge\",\n",
      "        \"location\": \"Orion City, Earth\",\n",
      "        \"employee_count\": 12500,\n",
      "        \"founding_year\": 2030,\n",
      "        \"is_public\": true,\n",
      "        \"valuation\": 15,\n",
      "        \"primary_focus\": \"quantum computing\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Zenith Robotics\",\n",
      "        \"location\": \"Neo New York, Earth\",\n",
      "        \"employee_count\": 10200,\n",
      "        \"founding_year\": 2027,\n",
      "        \"is_public\": true,\n",
      "        \"valuation\": null,\n",
      "        \"primary_focus\": \"AI robotics\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"AstraCom\",\n",
      "        \"location\": \"Hyperion City, Jupiter\",\n",
      "        \"employee_count\": 7800,\n",
      "        \"founding_year\": 2075,\n",
      "        \"is_public\": true,\n",
      "        \"valuation\": 5,\n",
      "        \"primary_focus\": \"telecommunications\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Vortex AI\",\n",
      "        \"location\": \"Neo London, Earth\",\n",
      "        \"employee_count\": 1100,\n",
      "        \"founding_year\": 2038,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": 5,\n",
      "        \"primary_focus\": \"AI consultancy\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Galactica Energy\",\n",
      "        \"location\": \"Ceres Station, Asteroid Belt\",\n",
      "        \"employee_count\": 3600,\n",
      "        \"founding_year\": 2062,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": 9,\n",
      "        \"primary_focus\": \"fusion power generation\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"NeuraNet\",\n",
      "        \"location\": \"Atlantis City, Pacific Ocean\",\n",
      "        \"employee_count\": 950,\n",
      "        \"founding_year\": 2022,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": 2,\n",
      "        \"primary_focus\": \"neural interface technologies\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Photonix Labs\",\n",
      "        \"location\": \"Solaris Base, Mercury\",\n",
      "        \"employee_count\": 2100,\n",
      "        \"founding_year\": 2060,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": 7,\n",
      "        \"primary_focus\": \"nanotechnology research\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Cenara Industries\",\n",
      "        \"location\": \"Arcadia, Venus\",\n",
      "        \"employee_count\": 7500,\n",
      "        \"founding_year\": 2065,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": 10,\n",
      "        \"primary_focus\": null\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"StellarWave Technologies\",\n",
      "        \"location\": \"Enceladus Base, Saturn\",\n",
      "        \"employee_count\": 1300,\n",
      "        \"founding_year\": 2055,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": 6,\n",
      "        \"primary_focus\": null\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Orbitix Systems\",\n",
      "        \"location\": \"Europa Station, Jupiter\",\n",
      "        \"employee_count\": 1900,\n",
      "        \"founding_year\": 2058,\n",
      "        \"is_public\": true,\n",
      "        \"valuation\": 4,\n",
      "        \"primary_focus\": \"satellite manufacturing\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Elysium Labs\",\n",
      "        \"location\": \"Vesper City, Venus\",\n",
      "        \"employee_count\": 1050,\n",
      "        \"founding_year\": 2068,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": 2,\n",
      "        \"primary_focus\": null\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"ExoLab Solutions\",\n",
      "        \"location\": \"Borealis, Pluto\",\n",
      "        \"employee_count\": 2400,\n",
      "        \"founding_year\": 2070,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": 3.1,\n",
      "        \"primary_focus\": \"DNA alteration technology\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Titanium Core Solutions\",\n",
      "        \"location\": \"Terra Nova, Mars\",\n",
      "        \"employee_count\": 9000,\n",
      "        \"founding_year\": 2049,\n",
      "        \"is_public\": true,\n",
      "        \"valuation\": 11,\n",
      "        \"primary_focus\": \"asteroid mining technologies\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Nexus Technologies\",\n",
      "        \"location\": \"Nova Tokyo, Earth\",\n",
      "        \"employee_count\": 8000,\n",
      "        \"founding_year\": 2043,\n",
      "        \"is_public\": true,\n",
      "        \"valuation\": 7.7,\n",
      "        \"primary_focus\": \"virtual reality\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Hyperion Solutions\",\n",
      "        \"location\": \"Olympia, Mars\",\n",
      "        \"employee_count\": 3200,\n",
      "        \"founding_year\": 2025,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": 9.8,\n",
      "        \"primary_focus\": \"machine learning advancements\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Elysium Labs\",\n",
      "        \"location\": \"San Francisco, Earth\",\n",
      "        \"employee_count\": 5001,\n",
      "        \"founding_year\": 2086,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": 7,\n",
      "        \"primary_focus\": null\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Polaris Innovations\",\n",
      "        \"location\": \"Cloud City, Venus\",\n",
      "        \"employee_count\": 1750,\n",
      "        \"founding_year\": 2035,\n",
      "        \"is_public\": false,\n",
      "        \"valuation\": null,\n",
      "        \"primary_focus\": \"atmospheric energy harvesting\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Type, TypeVar, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chat_models import AzureChatOpenAI  # Ensure correct import\n",
    "import tiktoken\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Define a generic type for Pydantic models\n",
    "T = TypeVar('T', bound=BaseModel)\n",
    "\n",
    "def extract_multi_needle(schema: Type[T], haystack: str, example_needles: List[str]) -> List[T]:\n",
    "    \"\"\"\n",
    "    Extracts and structures information from a large text corpus based on a given schema and examples.\n",
    "\n",
    "    Args:\n",
    "        schema (Type[T]): A Pydantic model defining the structure of the needle to be extracted.\n",
    "        haystack (str): The large text corpus to search through (haystack).\n",
    "        example_needles (List[str]): A list of example sentences (needles).\n",
    "\n",
    "    Returns:\n",
    "        List[T]: A list of extracted needles conforming to the provided schema.\n",
    "    \"\"\"\n",
    "    extracted_needles = []\n",
    "    model_name = 'gpt-4o-mini'  # Ensure this matches your deployment name\n",
    "\n",
    "    # Initialize the Azure OpenAI model\n",
    "    model = AzureChatOpenAI(\n",
    "        openai_api_version=os.environ.get(\"AZURE_OPENAI_VERSION\", \"2024-07-18\"),\n",
    "        azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o-mini\"),\n",
    "        azure_endpoint=os.environ.get(\n",
    "            \"AZURE_OPENAI_ENDPOINT\", \n",
    "            \"https://gptmini4o.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview\"\n",
    "        ),\n",
    "        openai_api_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"your_default_api_key_here\"),\n",
    "    )\n",
    "\n",
    "    # Initialize tokenizer\n",
    "    try:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")  # Use appropriate encoding\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing tokenizer: {e}\")\n",
    "        return extracted_needles\n",
    "\n",
    "    # Token limits\n",
    "    max_tokens_per_request = 128000\n",
    "    max_tokens_for_response = 1000\n",
    "    max_tokens_for_prompt = max_tokens_per_request - max_tokens_for_response\n",
    "\n",
    "    # Step 1: Pre-filter the haystack using keyword-based regex\n",
    "    # Define relevant keywords\n",
    "    keywords = [\n",
    "        'company', 'firm', 'corporation', 'startup', 'headquartered', \n",
    "        'founded', 'employees', 'valued at', 'established', 'based in', 'located in'\n",
    "    ]\n",
    "\n",
    "    # Build a regex pattern to find sentences containing any of the keywords\n",
    "    # This regex captures entire sentences that contain at least one keyword\n",
    "    keyword_pattern = r'\\b(?:' + '|'.join(map(re.escape, keywords)) + r')\\b'\n",
    "    sentence_pattern = re.compile(r'[^.!?]*' + keyword_pattern + r'[^.!?]*[.!?]', re.IGNORECASE)\n",
    "\n",
    "    # Find all candidate sentences\n",
    "    candidate_sentences = sentence_pattern.findall(haystack)\n",
    "\n",
    "    if not candidate_sentences:\n",
    "        print(\"No candidate sentences found using keyword-based pre-filtering.\")\n",
    "        return extracted_needles\n",
    "\n",
    "    print(f\"Found {len(candidate_sentences)} candidate sentences.\")\n",
    "\n",
    "    # Step 2: Batch candidate sentences into large chunks\n",
    "    # Join the candidate sentences into a single text\n",
    "    candidate_text = ' '.join(candidate_sentences)\n",
    "    candidate_tokens = encoding.encode(candidate_text)\n",
    "    num_tokens = len(candidate_tokens)\n",
    "\n",
    "    # Calculate the number of chunks\n",
    "    chunk_size = max_tokens_for_prompt  # 127,000 tokens\n",
    "    chunks = [\n",
    "        encoding.decode(candidate_tokens[i:i + chunk_size])\n",
    "        for i in range(0, num_tokens, chunk_size)\n",
    "    ]\n",
    "\n",
    "    print(f\"Split into {len(chunks)} chunks.\")\n",
    "\n",
    "    # Prepare schema description\n",
    "    schema_description = \"Extract information according to the following schema:\\n{\\n\"\n",
    "    for field_name, field in schema.__fields__.items():\n",
    "        field_descr = field.description or ''\n",
    "        field_type = (\n",
    "            field.annotation.__name__ if hasattr(field.annotation, '__name__') else str(field.annotation)\n",
    "        )\n",
    "        schema_description += f'  \"{field_name}\": \"{field_descr} ({field_type})\",\\n'\n",
    "    schema_description += \"}\\n\"\n",
    "\n",
    "    # Prepare examples\n",
    "    examples_text = \"Examples of the desired output format:\\n\"\n",
    "    for example in example_needles:\n",
    "        examples_text += f\"- {example}\\n\"\n",
    "\n",
    "    # System prompt\n",
    "    system_prompt = \"You are an AI language model that extracts structured data from text.\"\n",
    "\n",
    "    # Step 3: Process each chunk\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        user_prompt = (\n",
    "            f\"{schema_description}\\n\"\n",
    "            f\"{examples_text}\\n\"\n",
    "            f\"Text to analyze:\\n\\\"\\\"\\\"\\n{chunk}\\n\\\"\\\"\\\"\\n\"\n",
    "            \"Extract any instances matching the schema from the text above. \"\n",
    "            \"Provide the output as a JSON array of objects.\"\n",
    "        )\n",
    "\n",
    "        # Ensure the prompt fits within token limits\n",
    "        prompt_tokens = encoding.encode(user_prompt)\n",
    "        if len(prompt_tokens) > max_tokens_for_prompt:\n",
    "            print(f\"Prompt too long for chunk {idx}, skipping this chunk.\")\n",
    "            continue\n",
    "\n",
    "        # Call Azure OpenAI API\n",
    "        try:\n",
    "            response = model.invoke(\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            )\n",
    "            assistant_reply = response.content\n",
    "\n",
    "            # Parse the assistant's reply\n",
    "            try:\n",
    "                extracted_data = json.loads(assistant_reply)\n",
    "                if isinstance(extracted_data, list):\n",
    "                    for item in extracted_data:\n",
    "                        try:\n",
    "                            extracted_item = schema(**item)\n",
    "                            extracted_needles.append(extracted_item)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error parsing item: {item}, error: {e}\")\n",
    "                else:\n",
    "                    print(f\"Expected a list, got: {type(extracted_data)}\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error for chunk {idx}: {e}\")\n",
    "                print(\"Assistant reply:\")\n",
    "                print(assistant_reply)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with Azure OpenAI API for chunk {idx}: {e}\")\n",
    "            if \"rate limit\" in str(e).lower():\n",
    "                print(\"Rate limit exceeded. Sleeping for 60 seconds.\")\n",
    "                time.sleep(60)\n",
    "                continue\n",
    "            else:\n",
    "                print(\"An unexpected error occurred. Skipping this chunk.\")\n",
    "                continue\n",
    "\n",
    "    return extracted_needles\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    class TechCompany(BaseModel):\n",
    "        name: Optional[str] = Field(default=None, description=\"The full name of the technology company\")\n",
    "        location: Optional[str] = Field(default=None, description=\"City and country where the company is headquartered\")\n",
    "        employee_count: Optional[int] = Field(default=None, description=\"Total number of employees\")\n",
    "        founding_year: Optional[int] = Field(default=None, description=\"Year the company was established\")\n",
    "        is_public: Optional[bool] = Field(default=None, description=\"Whether the company is publicly traded (True) or privately held (False)\")\n",
    "        valuation: Optional[float] = Field(default=None, description=\"Company's valuation in billions of dollars\")\n",
    "        primary_focus: Optional[str] = Field(default=None, description=\"Main area of technology or industry the company focuses on\")\n",
    "\n",
    "    example_needles = [\n",
    "        \"Ryoshi, based in Neo Tokyo, Japan, is a private quantum computing firm founded in 2031, currently valued at $8.7 billion with 1,200 employees focused on quantum cryptography.\"\n",
    "    ]\n",
    "\n",
    "    # Read the haystack from a file\n",
    "    haystack_file = \"haystack.txt\"  # Ensure this file exists and is accessible\n",
    "    try:\n",
    "        with open(haystack_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            haystack = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Haystack file '{haystack_file}' not found.\")\n",
    "        haystack = \"\"\n",
    "\n",
    "    if haystack:\n",
    "        extracted_data = extract_multi_needle(TechCompany, haystack, example_needles)\n",
    "\n",
    "        for item in extracted_data:\n",
    "            print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Type, TypeVar, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chat_models import AzureChatOpenAI  # Ensure correct import\n",
    "import tiktoken\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Define a generic type for Pydantic models\n",
    "T = TypeVar('T', bound=BaseModel)\n",
    "\n",
    "def extract_multi_needle(schema: Type[T], haystack: str, example_needles: List[str]) -> List[T]:\n",
    "    \"\"\"\n",
    "    Extracts and structures information from a large text corpus based on a given schema and examples.\n",
    "\n",
    "    Args:\n",
    "        schema (Type[T]): A Pydantic model defining the structure of the needle to be extracted.\n",
    "        haystack (str): The large text corpus to search through (haystack).\n",
    "        example_needles (List[str]): A list of example sentences (needles).\n",
    "\n",
    "    Returns:\n",
    "        List[T]: A list of extracted needles conforming to the provided schema.\n",
    "    \"\"\"\n",
    "    extracted_needles = []\n",
    "    model_name = 'gpt-4o-mini'  # Ensure this matches your deployment name\n",
    "\n",
    "    # Initialize the Azure OpenAI model\n",
    "    model = AzureChatOpenAI(\n",
    "        openai_api_version=os.environ.get(\"AZURE_OPENAI_VERSION\", \"2024-07-18\"),\n",
    "        azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o-mini\"),\n",
    "        azure_endpoint=os.environ.get(\n",
    "            \"AZURE_OPENAI_ENDPOINT\", \n",
    "            \"https://gptmini4o.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview\"\n",
    "        ),\n",
    "        openai_api_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"your_default_api_key_here\"),\n",
    "    )\n",
    "\n",
    "    # Initialize tokenizer\n",
    "    try:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")  # Use appropriate encoding\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing tokenizer: {e}\")\n",
    "        return extracted_needles\n",
    "\n",
    "    # Token limits\n",
    "    max_tokens_per_request = 128000\n",
    "    max_tokens_for_response = 1000\n",
    "    max_tokens_for_prompt = max_tokens_per_request - max_tokens_for_response\n",
    "\n",
    "    # Step 1: Pre-filter the haystack using keyword-based regex\n",
    "    # Define relevant keywords\n",
    "    keywords = [\n",
    "        'company', 'firm', 'corporation', 'startup', 'headquartered', \n",
    "        'founded', 'employees', 'valued at', 'established', 'based in', 'located in'\n",
    "    ]\n",
    "\n",
    "    # Build a regex pattern to find sentences containing any of the keywords\n",
    "    # This regex captures entire sentences that contain at least one keyword\n",
    "    keyword_pattern = r'\\b(?:' + '|'.join(map(re.escape, keywords)) + r')\\b'\n",
    "    sentence_pattern = re.compile(r'[^.!?]*' + keyword_pattern + r'[^.!?]*[.!?]', re.IGNORECASE)\n",
    "\n",
    "    # Find all candidate sentences\n",
    "    candidate_sentences = sentence_pattern.findall(haystack)\n",
    "\n",
    "    if not candidate_sentences:\n",
    "        print(\"No candidate sentences found using keyword-based pre-filtering.\")\n",
    "        return extracted_needles\n",
    "\n",
    "    print(f\"Found {len(candidate_sentences)} candidate sentences.\")\n",
    "\n",
    "    # Step 2: Batch candidate sentences into large chunks\n",
    "    # Join the candidate sentences into a single text\n",
    "    candidate_text = ' '.join(candidate_sentences)\n",
    "    candidate_tokens = encoding.encode(candidate_text)\n",
    "    num_tokens = len(candidate_tokens)\n",
    "\n",
    "    # Calculate the number of chunks\n",
    "    chunk_size = max_tokens_for_prompt  # 127,000 tokens\n",
    "    chunks = [\n",
    "        encoding.decode(candidate_tokens[i:i + chunk_size])\n",
    "        for i in range(0, num_tokens, chunk_size)\n",
    "    ]\n",
    "\n",
    "    print(f\"Split into {len(chunks)} chunks.\")\n",
    "\n",
    "    # Prepare schema description\n",
    "    schema_description = \"Extract information according to the following schema:\\n{\\n\"\n",
    "    for field_name, field in schema.__fields__.items():\n",
    "        field_descr = field.description or ''\n",
    "        field_type = (\n",
    "            field.annotation.__name__ if hasattr(field.annotation, '__name__') else str(field.annotation)\n",
    "        )\n",
    "        schema_description += f'  \"{field_name}\": \"{field_descr} ({field_type})\",\\n'\n",
    "    schema_description += \"}\\n\"\n",
    "\n",
    "    # Prepare examples\n",
    "    examples_text = \"Examples of the desired output format:\\n\"\n",
    "    for example in example_needles:\n",
    "        examples_text += f\"- {example}\\n\"\n",
    "\n",
    "    # System prompt\n",
    "    system_prompt = \"You are an AI language model that extracts structured data from text.\"\n",
    "\n",
    "    # Step 3: Process each chunk\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        user_prompt = (\n",
    "            f\"{schema_description}\\n\"\n",
    "            f\"{examples_text}\\n\"\n",
    "            f\"Text to analyze:\\n\\\"\\\"\\\"\\n{chunk}\\n\\\"\\\"\\\"\\n\"\n",
    "            \"Extract any instances matching the schema from the text above. \"\n",
    "            \"Provide the output as a JSON array of objects.\"\n",
    "        )\n",
    "\n",
    "        # Ensure the prompt fits within token limits\n",
    "        prompt_tokens = encoding.encode(user_prompt)\n",
    "        if len(prompt_tokens) > max_tokens_for_prompt:\n",
    "            print(f\"Prompt too long for chunk {idx}, skipping this chunk.\")\n",
    "            continue\n",
    "\n",
    "        # Call Azure OpenAI API\n",
    "        try:\n",
    "            response = model.invoke(\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            )\n",
    "            assistant_reply = response.content\n",
    "\n",
    "            # Parse the assistant's reply\n",
    "            try:\n",
    "                extracted_data = json.loads(assistant_reply)\n",
    "                if isinstance(extracted_data, list):\n",
    "                    for item in extracted_data:\n",
    "                        try:\n",
    "                            extracted_item = schema(**item)\n",
    "                            extracted_needles.append(extracted_item)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error parsing item: {item}, error: {e}\")\n",
    "                else:\n",
    "                    print(f\"Expected a list, got: {type(extracted_data)}\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error for chunk {idx}: {e}\")\n",
    "                print(\"Assistant reply:\")\n",
    "                print(assistant_reply)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with Azure OpenAI API for chunk {idx}: {e}\")\n",
    "            if \"rate limit\" in str(e).lower():\n",
    "                print(\"Rate limit exceeded. Sleeping for 60 seconds.\")\n",
    "                time.sleep(60)\n",
    "                continue\n",
    "            else:\n",
    "                print(\"An unexpected error occurred. Skipping this chunk.\")\n",
    "                continue\n",
    "\n",
    "    return extracted_needles\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    class TechCompany(BaseModel):\n",
    "        name: Optional[str] = Field(default=None, description=\"The full name of the technology company\")\n",
    "        location: Optional[str] = Field(default=None, description=\"City and country where the company is headquartered\")\n",
    "        employee_count: Optional[int] = Field(default=None, description=\"Total number of employees\")\n",
    "        founding_year: Optional[int] = Field(default=None, description=\"Year the company was established\")\n",
    "        is_public: Optional[bool] = Field(default=None, description=\"Whether the company is publicly traded (True) or privately held (False)\")\n",
    "        valuation: Optional[float] = Field(default=None, description=\"Company's valuation in billions of dollars\")\n",
    "        primary_focus: Optional[str] = Field(default=None, description=\"Main area of technology or industry the company focuses on\")\n",
    "\n",
    "    example_needles = [\n",
    "        \"Ryoshi, based in Neo Tokyo, Japan, is a private quantum computing firm founded in 2031, currently valued at $8.7 billion with 1,200 employees focused on quantum cryptography.\"\n",
    "    ]\n",
    "\n",
    "    # Read the haystack from a file\n",
    "    haystack_file = \"haystack.txt\"  # Ensure this file exists and is accessible\n",
    "    try:\n",
    "        with open(haystack_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            haystack = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Haystack file '{haystack_file}' not found.\")\n",
    "        haystack = \"\"\n",
    "\n",
    "    if haystack:\n",
    "        extracted_data = extract_multi_needle(TechCompany, haystack, example_needles)\n",
    "\n",
    "        for item in extracted_data:\n",
    "            print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
